{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ceb5592",
   "metadata": {},
   "source": [
    "# Example tensorflow federated Notebook\n",
    "\n",
    "Important notes so that you can actually run the notebook\n",
    "```\n",
    "Python 3.9 is required to run the notebook (Warning, 3.8 doesn't work!)\n",
    "the requirements are\n",
    "    - tensorflow\n",
    "    - tensorflow-federated\n",
    "    - juypter\n",
    "```\n",
    "\n",
    "To run **TFF** in the notebook, it is required to run those two lines (this is notebook-specific)\n",
    "```\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add1f3d",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f1a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\" These two lines are required to make TFF work in a notebook!!!! \"\"\"\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe98c3c",
   "metadata": {},
   "source": [
    "####Â Example training on MNIST data (from the TFF homepage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b646a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 0.0\n",
      "progress = 0.025\n",
      "progress = 0.05\n",
      "progress = 0.075\n",
      "progress = 0.1\n",
      "progress = 0.125\n",
      "progress = 0.15\n",
      "progress = 0.175\n",
      "progress = 0.2\n",
      "progress = 0.225\n",
      "progress = 0.25\n",
      "progress = 0.275\n",
      "progress = 0.3\n",
      "progress = 0.325\n",
      "progress = 0.35\n",
      "progress = 0.375\n",
      "progress = 0.4\n",
      "progress = 0.425\n",
      "progress = 0.45\n",
      "progress = 0.475\n",
      "progress = 0.5\n",
      "progress = 0.525\n",
      "progress = 0.55\n",
      "progress = 0.575\n",
      "progress = 0.6\n",
      "progress = 0.625\n",
      "progress = 0.65\n",
      "progress = 0.675\n",
      "progress = 0.7\n",
      "progress = 0.725\n",
      "progress = 0.75\n",
      "progress = 0.775\n",
      "progress = 0.8\n",
      "progress = 0.825\n",
      "progress = 0.85\n",
      "progress = 0.875\n",
      "progress = 0.9\n",
      "progress = 0.925\n",
      "progress = 0.95\n",
      "progress = 0.975\n"
     ]
    }
   ],
   "source": [
    "# Load simulation data.\n",
    "source, _ = tff.simulation.datasets.emnist.load_data()\n",
    "def client_data(n):\n",
    "  return source.create_tf_dataset_for_client(source.client_ids[n]).map(\n",
    "      lambda e: (tf.reshape(e['pixels'], [-1]), e['label'])\n",
    "  ).repeat(10).batch(20)\n",
    "\n",
    "# Pick a subset of client devices to participate in training.\n",
    "train_data = [client_data(n) for n in range(3)]\n",
    "\n",
    "# Wrap a Keras model for use with TFF.\n",
    "def model_fn():\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(10, tf.nn.softmax, input_shape=(784,),\n",
    "                            kernel_initializer='zeros')\n",
    "  ])\n",
    "  return tff.learning.from_keras_model(\n",
    "      model,\n",
    "      input_spec=train_data[0].element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Simulate a few rounds of training with the selected client devices.\n",
    "trainer = tff.learning.build_federated_averaging_process(\n",
    "  model_fn,\n",
    "  client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.1))\n",
    "state = trainer.initialize()\n",
    "_states = []\n",
    "_metrics = []\n",
    "T = 40\n",
    "for t in range(T):\n",
    "    print(\"progress = {}\".format(t/T))\n",
    "    state, metrics = trainer.next(state, train_data)\n",
    "    _states.append(state)\n",
    "    _metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2548c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.897555"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = [m['train']['loss'] for m in metrics]\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34be5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b54dee86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)),\n",
       "             ('pixels',\n",
       "              TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_train.element_type_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37928c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aefc484a974f99362037d4bd21123034b1719ec2f8cc4f2696e8b213b538e45d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TFF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
